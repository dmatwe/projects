**Karpov.courses**
<br/>
[1. ФТ/НФТ](#к1)
<br/>
[2. high-lvl дизайн](#к2)
<br/>
[3. Модульный подход к дизайну](#к3)


**Маркетплейс**
<br/>
[1. high-lvl дизайн](#м1)
<br/>
[2. Модульный подход к дизайну](#м2)

**Сайта магазина премиальных предметов в онлайн-игре**
<br/>
[1. Выбор БД](#и1)


**Соц сеть заливки фото/видео**
<br/>
[1. Масштабирование](#ф1)
<br/>
[2. Повышение отзывчивости](#ф2)

**Приложение доставки еды**
<br/>
[1. Подсистемы поиска](#е1)

**Amazon**
<br/>
[1. Границы проекта](#a1)
<br/>
[2. ФТ/НФТ](#a2)
<br/>
[3. Оценка нагрузки ](#a3)
<br/>
[4. Высокоуровневый дизайн](#a4)
<br/>
[5. Компонентный дизайн](#a5)
<br/>
[6. Выбор хранилищ под систему](#a6)
<br/>
[7. Масштабируем сервис](#a7)
<br/>
[8. Повышение отзывчивости](#a8)
<br/>
[9. Мониторинг и взаимодействие с другими командами аналитики](#a9)
<br/>

***Функциональные требования***

1. Пользователи могут просматривать свою статистику по прохождению курса, чтобы восхищаться своими результатами 
2. Пользователи могут отправлять обратную связь по просмотренным урокам / заданиям и получать ответ если возникают вопросы или баги
3. Система должна рекомендовать курсы исходя из интересов и опыта пользователей, джун = аналитик данных, мидл = hard аналитика
4. Пользователю должна быть предоставлена возможность участвовать в программе лояльности, постоянным клиентам необходимы скидки, это повысит метрику retention 
5. Пользователю должна быть предоставлена возможность участвовать в реферальной программе, советовать хорошие курсы друзьям и получать за это плюшки в виде скидок, это увеличит метрику продаж 


***Нефункциональные требования***

1. Главная страница сайта по продаже курсов должна быть постоянно доступна, чтобы пользователь не пошел на Яндекс практикум.
2. Ответы в тестах и загруженные файлы ДЗ студентов должны сохраняться в бд после успешной отправки и не удаляться после обновления страницы, чтобы пользователи не тратили время на повторное решение.
3. Минимальное время задержки новой лекции - 5 минут, после недельного ожидания эти минуты не заметны.


***Cайт***
<a name="к2"></a>

Зачем нужен такой сервис? 

Чтобы продавать крутые курсы

***Первоочередные особенности***

1. Пользователи могут просматривать информацию по курсам и приобретать их (БД каталога курсов)
2. Система должна рекомендовать курсы на основе алгоритмов исходя из интересов пользователей анализируя их действия (БД действий пользователей)

***обучающая платформа LMS***

***Зачем нужен такой сервис?***

Студентам - Просматривать лекции курсов, читать конспекты, отправлять дз на проверку

Проверяющим - проверять ДЗ

***Первоочередные особенности***
1. Студенты могут смотреть лекции, читать конспекты и выполнять тестовые задания.  Данная информация хранится в БД учебного материала. 
2. В БД действий студентов ведется запись результатов прохождения курсов (кол-во баллов, кол-во пройденных тем и тд) и хранится вся справочная информация по студентам.
3. В БД файлов дз студентов хранятся проектные работы
4. Проверяющие ДЗ занимаются проверкой проектов студентов, которые хранятся в БД файлов ДЗ и начисляют баллы, начисление баллов осуществляется в БД действий 
5. Справочная информация и действия проверяющих хранится в БД действий проверяющих 

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/karpov-high.png)

***МОДУЛЬНЫЙ ПОДХОД К ДИЗАЙНУ***
<a name="к3"></a>

***Главная страница курса***

Роли: Модератор, клиент, Маркетолог

Модератор редактирует информацию по курсам через сервис редактирования курсов. Информация по курсам хранится в MongoDB, так как документная модель хорошо работает в системах управления контентом.

Клиент просматривает и покупает курсы используя сервис продажи курсов. Действия пользователей записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей.
Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями. 
После приобретения курса необходимо сразу же направить уведомление на почту клиента, для этого сервис продажи курсов взаимодействует с сервисом отправки уведомлений через очередь. 
RabbitMQ идеально подходит для веб-сервисов с низкими задержками.
Информация обо всех рассылках должна сохраняться на будущее на всякий случай в Redis -  быстрое хранилище пар «ключ‑значение».

Для массовых рассылок специальных предложений отдел маркетинга использует сервис маркетинга. Почты для рассылки берутся из БД Postgres, взаимодействие с сервисом отправки уведомлений осуществляется через очередь. 

***Портал КС***

Роли: Модератор, студент, проверяющий 

Модератор редактирует материал курсов через сервис редактирования контента. Контент хранится в MongoDB, так как документная модель хорошо работает в системах управления контентом.

Студент изучает материал курсов через сервис портала КС для студентов, действия студентов записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей.
Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями, а также для таких чувствительных данных как баллы за выполненные задания.

Для отправки проектов студенты используют сервис загрузки ДЗ, файлы отправляются через брокер Kafka, так как консьмер - сервис проверки ДЗ должен сам забирать (pull) записи из выбранного топика когда появляются свободные проверяющие.

Для принятия ДЗ проверяющие используют сервис проверки и после назначения проверяющего файл ДЗ попадает в хранилище amazon S3. Действия проверяющих записываются в Clickhouse. При проверке ДЗ проверяющий определяет кол-во баллов, запись ведется в Postgres.


![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/karpovb.png)


**Маркетплейс**
<a name="м1"></a>

***Зачем нужен такой сервис?***

Чтобы купить/продать товар

3 вида пользователей: покупатели, продавцы, модераторы 

***Первоочередные особенности***

1. Покупатели могут просматривать информацию по товарам (БД товаров), добавлять их в избарнное и приобретать (БД заказов). 
2. Система должна рекомендовать релевантные товары на основе алгоритмов анализируя действия пользователей (БД действий покупателей)
3. У крупного маркетплейса в периоды акций может быть большой наплыв пользователей (покупателей), поэтому можно сразу отметить наличие балансировщика нагрузки
4. Продавцы маркетплейса могут публиковать карточки с товарами, запись таких данных ведется в БД товаров 
5. Вся информаци и действия пользователей продавцов хранится в БД действий продавцов 
6. Для модерации карточек товаров и предотвращения фрода предусмотрен сервис модерации.


![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/market-high.png)


***МОДУЛЬНЫЙ ПОДХОД К ДИЗАЙНУ***
<a name="м2"></a>

***Маркетплейс***
Роли: Покупатель,  продавец, модераторы, маркетолог

***Покупатель***

1. У крупного маркетплейса в периоды акций может быть большой наплыв пользователей (покупателей), поэтому можно сразу отметить наличие балансировщика нагрузки и несколько серверов.
2. Для просмотра товаров покупатели используют сервис просмотра товаров, для оплаты - сервис оплаты.  Действия пользователей записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей. Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями. 
3. После оплаты заказ отправляется в сервис отправки товаров через брокер RabbitMQ для обработки заказа и создания трекномера. Сам заказ записывается в Бд Postgres (РУСБД применимы при множестве связей между сущностями). 
4. Также брокер RabbitMQ отправляет информацию о продаже товаров в сервис Инвентарь, который калькулирует остатки и заносит информацию в MongoDB каталог товаров (документная модель хорошо работает в системах управления контентом)
5. После успешного оформления заказа необходимо отправить уведомление клиенту. Сервис отправки товаров взаимодействует с сервисами отправки уведомлений через  брокер RabbitMQ. При высоких нагрузках количество консьюмеров сервисов уведомлений (воркеров), обрабатывающих сообщения можно увеличить.
6. Сервисы отправки уведомлений взаимодействуют с различными хендлерами уведомлений через  брокер RabbitMQ и с сервисом логирования уведомлений, который заносит всю историю уведомлений и рассылок в Redis ( быстрое хранилище пар «ключ‑значение».)

***Продавец***

1. Для публикации своих товаров продавцы используют сервис публикации товаров, который взаимодействует с сервисом инвентарь через брокер RabbitMQ.Действия пользователей записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей. 
2. Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями. 

***Модераторы***
Для модерации карточек товаров и предотвращения фрода со стороны покупателей предусмотрен сервисы модерации, у которых есть доступы к бд метаданных, действий пользователей и каталогу.

***Маркетолог***
Для массовых рассылок специальных предложений отдел маркетинга использует сервис маркетинга. Почты для рассылки берутся из БД Postgres, а выборка для рассылок формируется на основе действий пользователей и товаров попадающих под акции. взаимодействие с сервисом отправки уведомлений осуществляется через брокер RabbitMQ. 

***RabbitMQ***- отлично подходит для подобных фоновых задач, а также для коммуникации внутри приложений с сложной логикой.

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/marketb.png)




**Дизайн сайта магазина премиальных предметов в онлайн-игре**
<a name="и1"></a>

***Зачем нужен такой сервис?***

Чтобы купить/продать предметы

2 вида пользователей: покупатели и продавцы

***Первоочередные особенности?***

1. Покупатель и продавец может просматривать каталог предметов и фильтроваться по атрибутам и недавним позициям 
2. Продавец может выставлять свои предметы на продажу, а покупатель покупать
3. Покупателям и продавьцам доступна возможность чата между собой, пользователи могут обращаться либо к истории сообщений, либо вести беседы,  при беседе двух пользователей необходимо быстро доставлять их сообщения друг другу;


***Postgres*** - для хранение метаданных про пользователей и баланса монет у покупателей и продавцов тк данные чувствительны
<br/>
РУСБД применимы при множестве связей между сущностями. 

***MongoDB*** -  для хранения атрибутов предметов (каталог).
<br/>
Документная модель хорошо работает в системах управления контентом.

***Clichouse*** - для хранение истории действий покупателей и продавцов, а также всю историю сообщений покупателей и продавцов
<br/>
Колоночная БД лучше всего подходят для однотипных записей.

***Redis*** -  для хранения статусов пользователей,  недавних публикаций предметов и недавних сообщений между продавьцами и покупателями.
<br/>
Быстрое хранилище пар «ключ‑значение».

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/shopdb.png)




**Соц сеть заливки фото/видео**
<a name="ф1"></a>


![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/scale.png)

***Web Page***

1. Приходит много пользователей, и их запросы проходят через loadbalancer. Также существует его реплика, которая находится в режиме ожидания и будет работать в случае поломки основного балансировщика;
2. У веб-страницы есть много разных инстансов, которые должны отрабатывать запросы за адекватное время. Если один из них перестаёт отвечать, то опционально мы передаём информацию в автоскейлер, который создаст новый инстанс;
3. Балансировщик нагрузки выбирает наиболее свободный инстанс, которому передать входящий запрос;

***New Post Service***

1. Дополнительные балансировщики нагрузки и их копии для сервисов. У каждого сервиса также есть инстансы;
2. У сервиса New Post Service есть балансировщики, которые распределяют  передаваемый трафик для хранилищ
3. Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями.
4. Посты пользователей записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей, можно рассмотреть сценарий с «программными» JOIN-ами, когда все метаданные постов хранятся в колоночной БД, тк их проще масштабировать в отличии от РУСБД.
5. У баз данных есть реплики, которые помогут сервису продолжать работу в случае неполадок с оригинальной базой данных.
6. Для общения и интеграции между различными сервисами используется RabbitMQ, данный брокер идеально подходит для веб-сервисов с низкими задержками благодаря делегированию нагрузки множеству воркеров;

***Logging Service***

1. Логи заливки постов и сессии пользователей записываются в Redis -быстрое хранилище пар «ключ‑значение»
2. У Redis есть копия, которая хранится на жестком диске оффлайн на случай отказа основного инстанса

***Image Upload Service***

1. Сервис загрузки фотографий взаимодействует с распределенным хранилищем HDFS через балансировщик. HDFS поддерживает хранение разнообразных данных — структурированных (таблицы), полуструктурированных (JSON, XML) и неструктурированных (видео и изображения).
2. HDFS разбивает файлы на небольшие блоки и хранит их на разных узлах в кластере серверов по патрициям 

***Video Upload Service***

1. Сервис загрузки видео взаимодействует с сервисом обработчиком через RabbitMQ, брокер отлично подходит для фоновых и долгоиграющих задач вроде конвертации видео.

***Processing Service***

1. Сервис обработчик видео  взаимодействует с распределенным хранилищем HDFS через балансировщик. 
2. HDFS разбивает файлы на небольшие блоки и хранит их на разных узлах в кластере серверов по патрициям 


***Повышение отзывчивости***
<a name="ф2"></a>

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/index.png)


***Home Page***

1. Между пользователем и сервером кэш, чтобы каждый раз заново не запрашивать страницы.

***Home View Servie***

1. Когда запрашиваем профили, можем обращаться к кэшу, где хранятся недавние профили. 
2. Если есть необходимость обратиться к исходной базе, можем ее проиндексировать по ID юзера.
3. Метаданные пользователей хранятся в Postgres, РУСБД применимы при множестве связей между сущностями.


***Logging Servie***

1. Логи заливки постов и сессии пользователей записываются в Redis -быстрое хранилище пар «ключ‑значение».
2.  Redis и так довольно быстрое хранилище, поэтому кэш не сильно поможет  и операций на запись значительно больше, чем операций на чтение, в таком случае не стоит индексировать таблицу

***Post View Service***

1. Когда запрашиваем профили, можем обращаться к кэшу, где хранятся недавние посты. 
2. Если есть необходимость обратиться к исходной базе, можем ее проиндексировать по ID постов.
3. ID В качестве идентификатора поста может выступать 64-битное число, которое содержит в себе: зарезервированный бит, временную метку с момента создания сессии и тд.
4. Посты пользователей записываются в Clickhouse, колоночная БД лучше всего подходят для однотипных записей, можно рассмотреть сценарий с «программными» JOIN-ами, когда все метаданные постов хранятся в колоночной БД, тк их проще масштабировать в отличии от РУСБД.
5.  Для часто запрашиваемых медиа файлов вроде изображений, и видео используются инстансы CDN (распределённые хранилища данных, которые используются в крупных системах, покрывающих различные регионы и даже весь мир.)
6. Все медиафайлы хранятся в HDFS  - поддерживает хранение разнообразных данных — структурированных (таблицы), полуструктурированных (JSON, XML) и неструктурированных (видео и изображения).






***Подсистемы поиска в приложении доставки еды***
<a name="е1"></a>

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/search.png)


***Editor UI, Edit Service***

1. Редакторы заносят места для бронирования ресторанов и просмотра меню используя Edit Service.
2. MongoDB  используется для хранения таких атрибутов (наименование ресторана, адрес, описание, списки блюд. Документная модель хорошо работает в системах управления контентом.
3. Данные хранятся по шардам, секционирование повышает масштабируемость и производительность системы.

***Search UI, Content Search Service***

1. Приходит много пользователей, и их запросы проходят через loadbalancer. Также существует его реплика, которая находится в режиме ожидания и будет работать в случае поломки основного балансировщика;
2. Балансировщик нагрузки выбирает наиболее свободный и инстанс, которому передать входящий запрос;
3. Взаимодействие с другими сервисами происходит через балансировщик нагрузки

***Redis Cache Restaurants Menu***

1. В данной БД хранится наиболее релевантная информация по ресторанам и меню для пользователя
2. Если в кеше ничего нет, запрос перенапраавляется в главную БД MongoBD

***Logging Service***

1. Логи запросов пользователей записываются в Redis -быстрое хранилище пар «ключ‑значение»
2. У Redis есть копия, которая хранится на жестком диске оффлайн на случай отказа основного инстанса

***Indexing Geo Service***

1. Обращается к MongoD (для получения координат)/ Redis Logs (для получения статистики) и строит GeoHash / QuadTree в Geo Index 

***Indexing Auto Service***

1. Обращается к MongoD (для получения наименований блюд / ресторанов) / Redis Logs (для получения статистики) и строит и строит префиксное дерево 
2. Префиксное дерево хранится в отдельной БД Tree DB, а топовые результаты в кеше

***Geo search Servie***

1. Geo search Servie обращается к Geo Index для поиска ближайших ресторанов

***Autocomplete Servie***

1. Autocomplete Service обращается к кешу/БД префиксного дерева для автодополнения запроса






**Amazon**

***Границы проекта (Scope refinement)***
<a name="a1"></a>

1. Пощадка, где заказчик системы будет размещать свой товар и некий функционал, позволяющий пользователю посмотреть перечень товаров, ознакомиться с деталями позиции, положить товары в корзину и оплатить их.
2. в функционале не будет возможности пользователю зарегистрироваться и разместить на данной площадке свои товары для реализации (не marketplace).
3. Другие части бизнеса, к примеру, бухгалтерия, логистика, доставка товаров и т.д. выходят за рамки текущей системы.


***Функциональный требования (Functional Requirements)***
<a name="a2"></a>

1. Главная страница сайта с витриной товаров;
2. Поиск нужного товара;
3. Просмотр страницы товара;
4. Корзина и оплата заказа;
5. Управление заказами.

***Нефункциональные требования (Non-functional Requirements)***

1. Отзывчивость системы (быстрая загрузка страницы);
2. Высокая доступность (площадка всегда доступна);
3. Консистентность (товары видят все пользователи).


***Оценка нагрузки (Capacity Estimation)***
<a name="a3"></a>

1. MAU (Month Active Users) — 100M. 100 миллионов активных пользователей в месяц;
2. DAU (Daily Active Users) — 10M. 10 миллионов активных пользователей в день;
3. 100M goods.
4. Принимая во внимание, что наш сервис — это интернет-магазин, становится очевидным, что пользователи будут просматривать много контента — карточки товаров и изображения этих товаров. Возьмём в расчёт, что на каждой карточке товара присутствует 10 изображений, и примем, что активный пользователь ежедневно просматривает полностью 10 карточек и совершает 1 заказ.
5. 100 images views per active user daily;
6. 1 order per active user daily.

***Расчётные показатели по загрузке:***

1. 10M пользователей * 100 images / 100000 секунд в дне= 10000 RPS — чтение;
2. 10K / 100 = 100 RPS — запись. Формирование заказов.

***Сетевой трафик:***

1. 10000 секунд * 500KB (вес 1 изображения в карточке товара) = 5GB/s;
2. 5GB/s * 100000/s *400 day = 200PB трафика.


***Нагрузка на хранилище:***

1. 100M товаров * 10 изображений в карточке * 500KB = 500TB. При этом, если предусмотреть масштабирование, можем прибавить 20%.

***Нагрузка на вычислительные мощности:***

1. Чтение / запись <= 10 instances;
2. Сетевой трафик >= 40 instances;
3. Хранилище <= 100 SSD ~ 20 physical instances or ~ 100 cloud instances.

   
***Стоимость:***

1. $0.1 / gb * 200 000 000 GB = $20M;
2. 600TB * $300 = $180 000.

***Высокоуровневый дизайн***

<a name="a4"></a>

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/amazon.png)


***Компонентный дизайн***
<a name="a5"></a>

Компонентный дизайн представляет собой более детальную прорисовку модулей, подробную прорисовку взаимодействия с внешними сервисами относительно нашей системы, а также взаимодействия отдельных модулей между собой.

К внешним сервисам относим не только сервисы контрагентов, но и используемый компанией софт, который не является частью описываемой системы.

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/amazon_comp.png)

***Выбор хранилищ под систему***
<a name="a6"></a>

***MongoDB***
<br/>
Items — хранит в себе информацию о карточках товаров. Карточки имеют описательную структуру, у каждой карточки могут быть конкретные характеристики, подходящие только к ней. Поэтому здесь лучше всего подойдёт документная база данных типа MongoDB.

***MySQL***
<br/>
Users — содержит информацию о пользователях. Данные унифицированы, к ним должны применяться ACID требования. Потому здесь лучше использовать реляционные базы данных, например MySQL.
<br/>
Orders — содержит информацию о всех активных заказах за какой-то отрезок времени. С этими заказами пока ведётся работа внутренних служб и пользователей, поэтому под это хранилище лучше также выбрать MySQL.
<br/>
Carts — корзины пользователей. У каждого пользователя может быть только одна корзина, поэтому изначально можем использовать MySQL.

***Cassandra***
<br/>
Archive — содержит информацию о исполненных заказах. Для таких заказов может подойти колоночная база, например, Cassandra.

***Redis***
<br/>
Locks,  Inventory, Recoms — к этим хранилищам подойдут база данных типа key-value, например Redis. Locks хранит информацию о том, что единица товара заблокирована пользователем (находится на стадии оформления заказа) и не доступна другим пользователям. Inventory хранит информацию о количественных остатках товаров на складе. Recoms — это список рекомендаций для конкретного пользователя.


***Масштабируем сервис***

<a name="a7"></a>

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/amazon_scale.png)

Масштабирование — так как нагрузка будет довольно большой, у нас будет несколько подсервисов, то нужно распределять нагрузку между ними.

1. Первое — балансировщик нагрузки между UI элементами и соответствующими сервисами.
<br/>
Это позволит масштабировать отдельные сервисы независимо друг от друга.
<br/>
Чтобы нагрузка была равномерной, можно создать несколько инстансов для каждого сервиса.
<br/>
Также стоит добавить копию балансировщика, которая будет находиться в режиме ожидания до тех пор, пока основной балансировщик не выйдет из строя.
2. для MySQL или MongoDB шардировать данные, и т.к. нагрузка идёт больше на чтение, то можно добавить дополнительные реплики на чтение.
3. Cassandra и Redis — можно использовать какой-нибудь кластер несколько инстансов, которых будет достаточно для того, чтобы выдержать нагрузку.
<br/>
Если какая-то БД или сервис выходят из строя, мы можем заменить его другим инстансом.
<br/>
Когда перестаёт работать мастер-реплика, то одна из дополнительных реплик становится основной.
<br/>
Если выходит из строя и дополнительная, то мы добавляем еще одну новую реплику.
4. В случае Кассандры и Редиса у нас есть кластер со множеством инстансов, между ними используется консистентное кэширование,
<br/>
если инстанс упадёт, то добавляется новый инстанс, тогда данные перераспределяются между ними.
<br/>
Для редиса также можно добавить стэндбай копию, которая находится в режиме офлайн.

***Повышение отзывчивости***

<a name="a8"></a>

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/amazon_fb.png)

1. Чтобы ускорить доступ к данным, их можно кэшировать. Например, добавить между базой данных с пользователями и соответствующим сервисом кэш с пользователями. 
<br/>
Также можно использовать правило Парето и хранить 10% недавних активных пользователей в кэше. Такой же кэш можно добавить везде для обращений к базам данных.
<br/>
Кеш не нужен разве что для Redis с данными о брони, потому что доступ к нему и так достаточно быстрый.
2. Ещё один способ — индексирование для табличных баз данных. Это ускорит доступ к основной таблице по ключу.
<br/>
При этом не стоит забывать, что индексирование работает хуже, когда записей идет больше, чем чтения.
3. Для безопасности можно добавить файрвол, или же обратиться к соответствующей компании, которая будет фильтровать и допускать только полезные запросы, а не мусорный трафик.

***Мониторинг и взаимодействие с другими командами аналитики***

<a name="a9"></a>

1. Все наши сервисы так или иначе присылают логи в очередь сообщений о том, как они работают.
2. Эти логи затем попадают в Graphite, а через дэшборд Graphana все эти данные можно посмотреть на графике.
3. Для оповещений о проблемах нужен внутренний Notification provider, который будет присылать уведомления разработчикам.





**UBER** 

***Scope refinement***

1. Два типа пользователей сервиса
2. Входит: поиск, совершение поездки и история поездок
3. Не входит: поиск маршрута и расчет стоимости

***Функциональные требования***

***Пешеход***

1. Управление профилем (оплата, история поездок);
2. Выбрать точку старта поездки (текущая локация);
3. Увидеть машины поблизости и время ожидания;
4. Выбрать пункт назначения и сделать заказ;
5. Отслеживание и управление поездкой.

***Водитель***
1. Управление профилем (оплата, история поездок);
2. Выход на смену и ее завершение;
3. Принять входящий заказ поблизости;
4. Отслеживание и управление поездкой.

***Дополнительно***

1. Рейтинг водителей и пешеходов;
2. Отслеживание спроса и прайсинг (ML);
3. Служба поддержки и контроль качества.


***Нефункциональные требования***

1. Доступность > консистентность;
2. Пешеход быстро находит водителя;
3. Водитель не простаивает без дела;
4. Расстояние между пешеходом и водителем небольшое.

***Оценка нагрузки***

***Трафик***

1. 100М пешеходов всего;
2. 4М водителей всего;
3. В среднем за день 5% пешеходов оформляют по 2 поездки (5М daily active walkers (DAW) х 2 поездки) = 10М поездок в день;
4. В среднем за день 1М активных водителей (1М daily active drivers).

***Запросы (load)***

1. (Считая, что в дне около 100k секунд) 10М поездок / 100k секунд = 10k поисков в секунду;
2. Поиск в среднем длится 10 секунд. 100k одновременных поисков;
3. На каждый поиск опрашиваем 10 водителей = 1М соединений;
4. (Считая, что поездка в среднем длится 15 мин) 10М поездок / 24 часа / 4 части = 100k одновременных поездок;
5. Каждые 5 сек водители сообщают свое местоположение. 0.2 R/D/s (запроса от водителя в секунду) x 1M водителей = 200k RPS.


***Сетевая нагрузка***

1. Во время поиска водители отображаются на карте. Каждый водитель имеет 10 подписок на основе ближайших локаций: 10 подписок х 1М водителей = 10М;
2. Предположим, что ID водителя вмешается в 4 байта, а локация - по 8 для lat и lng. По каждой подписке передаём эту информацию. 10М подписок х (4 + 8 + 8) = 200 MB/s;
3. 200 MB/s x 100k секунд в дне х 2000 дней (в пяти годах) = 40PB информации.

***Хранилище***

1. Профили водителей: 100KB x 4M водителей = 400 GB;
2. Профили пешеходов: 100KB x 100M пешеходов = 10 TB;
3. Местоположения: 1М (активных водителей) х (4 + 8 + 8) + 5М (активных пешеходов) х (8 (на ID, так как пешеходов больше) + 8 + 8) = 200 MB;
4. Соединения по подпискам: 1M x 4B (на ID) + 10M x 8B = 100 MB;
5. Поездка: местоположение (0.2 R/D/s x 1000 s (~15 мин) х 16B + 1KB на инфо о водителе и тд) x 10M поездок x 2000 дней = 100 PB.

***Затраты***
1. Conn/band: 100 инстансов х $100 x 60 месяцев х перекрытие 3 для надёжности = $2M на сервера;
2. Трафик: $0.1 / GB x 40 PB = $4M;
3. Хранение: $300 / TB x 200 TB = $60k на медленное хранилище + $20k на быстрые хранилища;
4. Итого около $6M.

***Высокоуровневый дизайн***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/uber_high_lvl.png)

***Дизайн компонентов и выбор БД***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/uber_comp.png)

***Масштабируемость и надёжность***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/uber_scale.png)

***Мониторинг и взаимодействие***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/uber_mon.png)


**Tinder**


***Границы проекта (Scope refinement)***

Дейтинговый сервис, в котором пользовтаели могут создавать и просматривать  анкеты, ставить лайк/дизлайк, матчиться при взаимном лайке, вести диалоги, получать уведомления, редактировать свой профиль, загружать в него фото/видео.
2 роли: пользователи, маркетологи

***Функциональный требования (Functional Requirements)***

1.	Создавать / редактировать профиль, загружать в свою анкету фото/видео.
2.	Просматривать чужие анкеты, ставить  лайк/дизлайк 
3.	Матчить пользователей при взаимном лайке
4.	Real-time чат между совпавшими парами 
5.	Возможность поиска анкет по геолокации и фильтрам предпочтений
6.	Рекомендации анкет для увеличения вероятности совпадений;
7.	Направлять уведомления при совпадениях и промо-пушей;
8.	Возможность покупки подписки для расширенных возможностей (просмотр лайков своей анкеты, увеличенный лимит просмотра чужих анкет)


***Нефункциональные требования (Non-functional Requirements)***

1.	Отзывчивость системы (быстрая загрузка приложения, чтобы пользователь не ушел к конкурентам);
2.	Высокая доступность (приложение всегда доступно);
3.	Доступность > консистентность при просмотре анкет;
4.	Высокая надёжность сервиса — анкеты не должны потеряться
5.	Общение происходит в реальном времени с минимальными задержками;
6.	Консистентность — одинаковые сообщения в чатах на всех устройствах;
7.	Большая нагрузка ожидается на системы хранения и поиска на основе геолокации при большом количестве юзеров, в кластеризованных в городах;
8.	Необходимо шардировать данные по городам
9.	Интеграция с внешними сервисами при регистрации (возможность авторизации через Google аккаунт/ соц. Сети, apple id)


| Вводные данные                                                                                                 | Значение         | Ед. измерения |
| -------------------------------------------------------------------------------------------------------------- | ---------------- | ------------- |
| USER COUNT<br>Пользователей всего                                                                              | 1 000 000 000,00 |               |
| MAU<br>Monthly active users                                                                                    | 100 000 000,00   |               |
| DAU<br>Daily active users                                                                                      | 10 000 000,00    |               |
| Media Profile<br>Кол-во медиафайлов в профиле юзера                                                            | 10               |               |
| Media WEIGHT<br>Вес одного медиафайла                                                                          | 100              | KB            |
| READ Profile<br>Просмотр анкет активным пользователем за день                                                  | 100              |               |
| UPDATE Media<br>Обновление медиафайла в профиле в день                                                         | 1                |               |
| INSERT Message<br>Отправка сообщений                                                                           | 300              |               |
| Read Message<br>Чтение сообщений                                                                               | 2                |               |
| Message WEIGHT<br>Вес одного медиафайла                                                                        | 1                | KB            |
| GEO WEIGHT<br>ID пользователя вмешается в 4 байта,<br>а локация - по 8 для lat и lng.<br>(4 + 8 + 8) = 20 Byte | 0,02             | KB            |


| Вычисления                                                                                                              |             |
| ----------------------------------------------------------------------------------------------------------------------- | ----------- |
| Вычислительная нагрузка                                                                                                 |             |
| RPS INSERT Profile (Обновление медиафайла в анкете)<br>Формула:<br>(DAU X UPDATE Media) / Кол-во сек в дне              | 115,74      |
| RPS READ Profile (Просмотр анкет с медиафайлами)<br>Формула:<br>(DAU X READ Profile X Media Profile) / Кол-во сек в дне | 115740,74   |
| RPS INSERT Message (Отправка сообщений)<br>Формула:<br>(DAU X INSERT Message) / Кол-во сек в дне                        | 34722,22222 |
| RPS READ Message<br>Формула:<br>(DAU X INSERT Message X READ Message) / Кол-во сек в дне                                | 69444,44444 |
| Geo INSERT<br>Каждые 12 сек передача гео от пользователей<br>Формула:<br>1/12 X DAU                                     | 833333,3333 |
| RPS Всего                                                                                                               | 1053356,48  |


| Cеть / Трафик                                                             |             |           |           |        |        |
| ------------------------------------------------------------------------- | ----------- | --------- | --------- | ------ | ------ |
| Ед. измерения                                                             | KB          | Mbps      | MBps      | Gbps   | GBps   |
| INSERT Profile per/sec<br>Формула: RPS INSERT Profile X Media WEIGHT      | 11574,1     | 92,593    | 11,574    | 0,093  | 0,012  |
| INSERT Message per/sec<br>Формула:<br>RPS INSERT Message X Message WEIGHT | 34722,2     | 277,778   | 34,722    | 0,278  | 0,035  |
| READ Profile per/sec<br>Формула:<br>RPS READ Profile X Media WEIGHT       | 11574074,1  | 92592,593 | 11574,074 | 92,593 | 11,574 |
| READ Message per/sec<br>Формула:<br>RPS READ Message X Message WEIGHT     | 69444,4     | 555,556   | 69,444    | 0,556  | 0,069  |
| GEO INSERT per/sec<br>Формула:<br>GEO INSERT X GEO WEIGHT                 | 16666,66667 | 133,333   | 16,667    | 0,133  | 0,017  |
| Кол-во соединений = RPS Всего<br>                                         | 1053356,481 |           |           |        |


| Хранилище                                                                              |                |                |               |             |            |          |         |        |
| -------------------------------------------------------------------------------------- | -------------- | -------------- | ------------- | ----------- | ---------- | -------- | ------- | ------ |
| Ед. измерения                                                                          | KB             | Mb             | MB            | Gb          | GB         | Tb       | TB      | Pb     |
| INSERT Profile На горизонте 5 лет<br>Формула:<br>X 5 лет X 365 дней X Кол-во сек в дне | 1825000000000  | 14600000000    | 1825000000    | 14600000    | 1825000    | 14600    | 1825    | 14,6   |
| INSERT Message На горизонте 5 лет<br>Формула:<br>X 5 лет X 365 дней X Кол-во сек в дне | 5475000000000  | 43800000000    | 5475000000    | 43800000    | 5475000    | 43800    | 5475    | 43,8   |
| READ Profile На горизонте 5 лет Формула:<br>X 5 лет X 365 дней X Кол-во сек в дне      | 1,825E+15      | 14600000000000 | 1825000000000 | 14600000000 | 1825000000 | 14600000 | 1825000 | 14600  |
| READ На горизонте 5 лет<br>Формула:<br>X 5 лет X 365 дней X Кол-во сек в дне           | 10950000000000 | 87600000000    | 10950000000   | 87600000    | 10950000   | 87600    | 10950   | 87,6   |
| GEO INSERT На горизонте 5 лет<br>Формула:<br>X 5 лет X 365 дней X Кол-во сек в дне     | 2628000000000  | 21024000000    | 2628000000    | 21024000    | 2628000    | 21024    | 2628    | 21,024 |
| Хранение всех файлов<br>Формула:<br>Всего пользователей X Всего файлов X Вес           | 1000000000000  | 8000000000     | 1000000000    | 8000000     | 1000000    | 8000     | 1000    | 8      |


| Стоимость                                                                                                      | $               |
| -------------------------------------------------------------------------------------------------------------- | --------------- |
| Трафик (1GB = 0.1$)                                                                                            | $183 857 800,00 |
| Хранение данных ($30 / TB )                                                                                    | $249 000,00     |
| Кол-во серверов                                                                                                |                 |
| Кол-во серверов для хранения<br>MAX: SSD 50 TB - 1 сервер                                                      | 166,0           |
| Кол-во серверов для удержания соединений<br>MAX: 100 000 соединений<br>Формула:<br>Кол-во соединений / 100 000 | 105,3           |
| Кол-во серверов для сетевого трафика<br>MAX: 1GbE/SEC<br>Формула:<br>Трафик per/sec / 1 Gb                     | 93,7            |
| Всего серверов                                                                                                 | 365,0           |
| Стоимость серверов на 5 лет<br>365 инстансов х $100 x 60 месяцев х перекрытие 3 для надёжности                 | $6 569 775,00   |


![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/tinder1.png)

***Описание компонентов***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/tinder2.png)


***Marketing UI (UI маркетинговых рассылок)***

1. Analytic Service – сервис аналитики тарифов и заказов пользователей
2. Marketing Notification Service – сервис отправки промо-пушей, взаимодействует с хендлерами отправки пушей (Email Handler Service, SMS Handler Service, Push Handler Service) через брокер сообщений

***Subscribe UI - UI покупки подписок***

1. Subscribe service – сервис просмотра тарифов на подписки 
2. Checkout service – сервис оформления подписки
3. Payment service – сервис оплаты

***Profile UI - UI редактирования профиля***

1. User service – сервис управления профилем
2. Post service – сервис загрузки медиаконтента в профиль,  взаимодействует с другими сервисами через брокер сообщений
3. Photo upload service – сервис загрузки изображений 
4. Video upload service - сервис загрузки видео, взаимодействует с сервисом обработчиком видео (Video processing Service)  через брокер сообщений
5. Logging profile service – сервис сбора логов пользователей
6. Login  Notification  service – сервис отправки кодов для авторизации , взаимодействует с хендлерами отправки пушей (Email Handler Service, SMS Handler Service, Push Handler Service) через брокер сообщений


***Registration UI - UI регистрации***

1. Registration service – сервис регистрации, взаимодействует с внешними сервисами авторизации (Verification service), позволяет авторизироваться через соц. Сети и тп
2. ID Generator – сервис для генерации ID новых пользователей
3. Notification Logger  service – логирует все рассылки 
4. GEO Handler – хендлер для сбора гео у пользователей 
5. Location Service – сервис определения местоположения пользовталей 

***Search UI - UI просмотра анкет***

1. Search service – сервис поиска анкет
2. Like/dislike logger service – сервис сбора лайков/дизлайков пользователей
3. Recommendation service – сервис с алгоритмами рекомендаций
4. Merge service – сервис мерджа анкет
5. Merge/Messages Notification  service – сервис для отправки пушей при совпадении пар / получении новых сообщений, взаимодействует с хендлерами отправки пушей (Email Handler Service, SMS Handler Service, Push Handler Service) через брокер сообщений

***Messages UI - UI диалогов***

1. Chat Service  - сервис чата
2. Online checker Service -  сервис мониторинга онлайна пользователей 
3. Media service – сервис отправки медиаконтента в чат, взаимодействует с другими сервисами через брокер сообщений

***Выбор БД***


***MySQL*** - для хранения метаданных про пользователей и баланса монет у покупателей и продавцов тк данные чувствительны РУСБД применимы при множестве связей между сущностями.

1.	Users – метаданные пользователей
2.	Orders – бд заказов

***MongoDB*** - для хранения атрибутов предметов (каталог). Документная модель хорошо работает в системах управления контентом.

1.	Subscriptions Tariffs – каталог тарифов на подписки 

***HDFS*** - Все медиафайлы хранятся в HDFS - поддерживает хранение разнообразных данных — структурированных (таблицы), полуструктурированных (JSON, XML) и неструктурированных (видео и изображения).

1.	Video -  хранилище видео 
2.	Images – хранилище изображений 

***Clickhouse*** - для хранение истории действий пользователей, а также для истории сообщений. Колоночная БД лучше всего подходят для однотипных записей.

1.	Like/Dislike – лайки/дизлайки анкет
2.	Merges – совпадения анкет
3.	Messages - сообщения

***Custom – кастомная БД***

1.	QuandTree – квадродерево для хранения гео пользователей

***Redis*** - для хранения статусов пользователей, недавних сообщений, позиций
1.	Logs – логи пользователей 
2.	Positions – актуальная локация пользователей
3.	Notifications – логи рассылок
4.	Status – статусы пользователей онлайн/оффлайн


***Масштабирование***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/tinder3.png)


так как нагрузка будет довольно большой, у нас будет несколько подсервисов, то нужно распределять нагрузку между ними. 

1.	Балансировщик нагрузки между UI элементами, соответствующими сервисами и базами данных. Это позволит масштабировать отдельные сервисы независимо друг от друга. 
2.	Чтобы нагрузка была равномерной, можно создать несколько инстансов для каждого сервиса. 
3.	Также стоит добавить копию балансировщика, которая будет находиться в режиме ожидания до тех пор, пока основной балансировщик не выйдет из строя. 
4.	для MySQL и MongoDB шардировать данные, и т.к. нагрузка идёт больше на чтение, то можно добавить дополнительные реплики на чтение. 
5.	Clickhouse, Redis,  QuandTree Custom— можно использовать какой-нибудь кластер несколько инстансов, которых будет достаточно для того, чтобы выдержать нагрузку. Если какая-то БД или сервис выходят из строя, мы можем заменить его другим инстансом. Когда перестаёт работать мастер-реплика, то одна из дополнительных реплик становится основной. Если выходит из строя и дополнительная, то мы добавляем еще одну новую реплику. 
6.	В случае Clickhouse и Redis у нас есть кластер со множеством инстансов, между ними используется консистентное кэширование, если инстанс упадёт, то добавляется новый инстанс, тогда данные перераспределяются между ними. 
7.	Для Redis также можно добавить стэндбай копию, которая находится в режиме офлайн.
8.	Для запрашиваемых медиа файлов вроде изображений, и видео используются инстансы CDN (распределённые хранилища данных, которые используются в крупных системах, покрывающих различные регионы и даже весь мир.)
9.	HDFS разбивает файлы на небольшие блоки и хранит их на разных узлах в кластере серверов по патрициям
10.	Cache – для просмотра недавних сообщений

***Мониторинг, взаимодействие с другими командами и безопасность***

![Image alt](https://github.com/dmatwe/projects/blob/main/System_design/проекты/png/tinder4.png)


1.	Все наши сервисы так или иначе присылают логи в очередь сообщений о том, как они работают. Эти логи затем попадают в Graphite, а через дэшборд Grafana все эти данные можно посмотреть на графике. 
2.	Для оповещений о проблемах нужен внутренний Notification provider, который будет присылать уведомления разработчикам.

Так может выглядеть взаимодействие с командой ML инженеров: 
1.	сырые данные предобрабатываются и передаются на хранение в MLкластер; 
2.	с применением ресурсов MLкластера по расписанию обучаются новые модели; 
3.	также разработчики проводят эксперименты по улучшению моделей и обучению новых; 
4.	задания периодически обрабатывают данные и передают результаты в нашу систему.
5.	User prioritizer service – создает выборку пользователей (Embendings) на основе действий и местоположения и передает информацию в сервис рекомендаций
6.	Anti-fraud service – вычисляет злоумышленников
7.	Файрволы ограничивают возможность обработки запросов. В модуле устанавливают конкретные IP-адреса, порты или конкретных пользователей, с которых можно обрабатывать запрос. Если запрос пришел с другого порта или адреса, он не пройдёт к серверу.
